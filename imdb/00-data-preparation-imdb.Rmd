---
title: "imdb-dataset"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## IMDB dataset

50,000 highly-polarized reviews from the Internet Movie Database. They are split into 25,000 reviews for training and 25,000 reviews for testing, each set consisting in 50% negative and 50% positive reviews.


```{r}
library(keras)
# imdb <- dataset_imdb(num_words = 10000)
# saveRDS(imdb, "data/imdb.rds")
imdb <- readRDS("data/imdb.rds")
```

Load training sets

```{r}
train_data <- imdb$train$x
train_labels <- imdb$train$y
test_data <- imdb$test$x
test_labels <- imdb$test$y
```

The variables `train_data` and `test_data` are lists of reviews; each review is a list of word indices (encoding a sequence of words). 
`train_labels` and `test_labels` are lists of 0s and 1s, where 0 stands for negative and 1 stands for positive.


```{r}
str(train_data[[1]])
```

Because you’re restricting yourself to the top 10,000 most frequent words, no word index will exceed 10,000:

```{r}
max(sapply(train_data, max))
```


## Preparing the data

You can’t feed lists of integers into a neural network. You have to turn your lists into tensors. There are two ways to do that:

1) Pad your lists so that they all have the same length, turn them into an integer tensor of shape (samples, word_indices), and then use as the first layer in your network a layer capable of handling such integer tensors

2)  One-hot-encode your lists to turn them into vectors of 0s and 1s. This would mean, for instance, turning the sequence [3, 5] into a 10,000-dimensional vector that would be all zeros except for indices 3 and 5, which would be ones. Then you could use as the first layer in your network a dense layer, capable of handling floating-point vector data.

Let’s go with the latter solution and vectorize the data, which you’ll do manually for maximum clarity.

```{r}
vectorize_sequences <- function(sequences, dimension = 10000) {
  # Create an all-zero matrix of shape (len(sequences), dimension)
  results <- matrix(0, nrow = length(sequences), ncol = dimension)
  for (i in 1:length(sequences))
    # Sets specific indices of results[i] to 1s
    results[i, sequences[[i]]] <- 1
  results
}
# Our vectorized training data
x_train <- vectorize_sequences(train_data)
# Our vectorized test data
x_test <- vectorize_sequences(test_data)
```

```{r}
str(x_train[1,])
```
We should also vectorize our labels, which is straightforward:

```{r}
# Our vectorized labels
y_train <- as.numeric(train_labels)
y_test <- as.numeric(test_labels)

```


```{r}
save(x_train, x_test, y_train, y_test, file = "imdb_data.RDS")
```



